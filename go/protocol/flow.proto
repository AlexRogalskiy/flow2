syntax = "proto3";

package flow;

import "broker/protocol/protocol.proto";
import "consumer/protocol/protocol.proto";
import "consumer/recoverylog/recorded_op.proto";
import "ptypes/empty/empty.proto";
import "gogoproto/gogo.proto";

option go_package = "protocol";

option (gogoproto.marshaler_all) = true;
option (gogoproto.protosizer_all) = true;
option (gogoproto.unmarshaler_all) = true;

// UUIDParts is a deconstructed, RFC 4122 v1 variant Universally Unique
// Identifier as used by Gazette.
message UUIDParts {
  option (gogoproto.equal) = true;

  // Producer is the unique node identifier portion of a v1 UUID, as the high
  // 48 bits of |producer_and_flags|. The MSB must be 1 to mark this producer
  // as "multicast" and not an actual MAC address (as per RFC 4122).
  //
  // Bits 49-54 must be zero.
  //
  // The low 10 bits are the 10 least-significant bits of the v1 UUID clock
  // sequence, used by Gazette to represent flags over message transaction
  // semantics.
  fixed64 producer_and_flags = 1;
  // Clock is a v1 UUID 60-bit timestamp (60 MSBs), followed by 4 bits of
  // sequence counter.
  fixed64 clock = 2
      [ (gogoproto.casttype) = "go.gazette.dev/core/message.Clock" ];
}

// Document is a standardized runtime representation of an Estuary document.
// It holds a super-set of properties used by various APIs in processing
// documents, and not all properties need be set in a given API context.
message Document {
  // The begin offset of the document within the journal, if applicable.
  int64 begin = 1
      [ (gogoproto.casttype) = "go.gazette.dev/core/broker/protocol.Offset" ];
  // The end offset of the document within the journal, if applicable.
  int64 end = 2
      [ (gogoproto.casttype) = "go.gazette.dev/core/broker/protocol.Offset" ];
  // ContentType is the encoding used for Document |content|.
  enum ContentType {
    INVALID = 0;
    JSON = 1;
    // Future ContentTypes may include CBOR or tape-based representations.
  };
  ContentType content_type = 3;
  // Content of the document, encoded under the accompanying ContentType.
  bytes content = 4;
  // UUIDParts of this document.
  UUIDParts uuid_parts = 5 [ (gogoproto.nullable) = false ];
  // Shuffle records a shuffling outcome of mapping this Document into a ring
  // of readers. Documents may be shuffled to multiple ring locations with
  // the same or different transforms. They may also be mapped to a specific
  // location with multiple transforms (or both!).
  message Shuffle {
    // Index within the worker ring to which the document is shuffled.
    uint32 ring_index = 1;
    // Transform ID to which the document is shuffled.
    uint32 transform_id = 2;
    // Highest-random weight from rendezvous hashing the document into the ring.
    fixed32 hrw = 3;
  }
  // Shuffles is the set of Shuffle outcomes for this Document.
  // It must be ordered and unique on ascending (ring_index, transform_id).
  repeated Shuffle shuffles = 8 [ (gogoproto.nullable) = false ];
}

message Ring {
  option (gogoproto.equal) = true;

  // Unique name of this ring.
  string name = 1;
  // Current members of this ring.
  message Member {
    option (gogoproto.equal) = true;

    // Miniumum Clock of messages processed by this member, used to:
    // - Lower-bound messages mapped to this member.
    // - Lower-bound the fragment from which this member starts reading.
    uint64 min_msg_clock = 1
        [ (gogoproto.casttype) = "go.gazette.dev/core/message.Clock" ];
    // Maximum Clock of messages processed by this member, used to
    // upper-bound messages mapped to this member.
    uint64 max_msg_clock = 2
        [ (gogoproto.casttype) = "go.gazette.dev/core/message.Clock" ];
  }
  repeated Member members = 2 [ (gogoproto.nullable) = false ];
}

message ShuffleConfig {
  option (gogoproto.equal) = true;
  // Journal to be shuffled.
  string journal = 1
      [ (gogoproto.casttype) = "go.gazette.dev/core/broker/protocol.Journal" ];
  // Ring on whose behalf this journal is being shuffled.
  Ring ring = 3 [ (gogoproto.nullable) = false ];
  // Coordinator is the ring member index which is responsible for shuffled
  // reads of this journal.
  uint32 coordinator = 4;
  // Shuffles applied to journal documents, mapping each document to
  // indicies within the |ring|.
  message Shuffle {
    option (gogoproto.equal) = true;

    // Transform ID for which this Shuffle is being applied.
    int64 transform_id = 1;
    // Composite key over which shuffling occurs, specified as one or more
    // JSON-Pointers indicating a message location to extract.
    repeated string shuffle_key_ptr = 2;
    // Number of top-ranked processors to broadcast each message to, after
    // shuffling. Usually this is one. If non-zero, |choose_from| cannot be set.
    uint32 broadcast_to = 3;
    // Number of top-ranked readers from which a single reader index will be
    // selected, after shuffling. The message Clock value is used to pseudo
    // randomly pick the final index, making the selection deterministic.
    // Values larger than one can be used to distribute "hot keys" which might
    // otherwise overwhelm specific readers.
    // Usually this is zero and |broadcast_to| is used instead. If non-zero,
    // |broadcast_to| cannot be set.
    uint32 choose_from = 4;
  }
  repeated Shuffle shuffles = 5 [ (gogoproto.nullable) = false ];
}

// ShuffleRequest is the request message of a Shuffle RPC.
message ShuffleRequest {
  option (gogoproto.equal) = true;

  ShuffleConfig config = 1 [ (gogoproto.nullable) = false ];

  // Index of this member within the ring.
  uint32 ring_index = 2;
  // Offset to begin reading the journal from.
  int64 offset = 3
      [ (gogoproto.casttype) = "go.gazette.dev/core/broker/protocol.Offset" ];
  // Offset to stop reading the journal at, or zero if unbounded.
  int64 end_offset = 4
      [ (gogoproto.casttype) = "go.gazette.dev/core/broker/protocol.Offset" ];
  // Resolution header of the |config.coordinator_index| shard.
  protocol.Header resolution = 5;
}

// ShuffleResponse is the streamed response message of a Shuffle RPC.
message ShuffleResponse {
  // Status of the Shuffle RPC.
  consumer.Status status = 1;
  // Header of the response.
  protocol.Header header = 2;
  // Documents included in this ShuffleResponse.
  repeated Document documents = 3 [ (gogoproto.nullable) = false ];
  // Terminal error encountered while serving this ShuffleRequest. A terminal
  // error is only sent if a future ShuffleRequest of this same configuration
  // and offset will fail in the exact same way, and operator intervention is
  // required to properly recover. Such errors are returned so that the caller
  // can also abort with a useful, contextual error message.
  //
  // Examples of terminal errors include the requested journal not existing,
  // or data corruption. Errors *not* returned as |terminal_error| include
  // network errors, process failures, and other conditions which can be
  // retried.
  string terminal_error = 4;
  // Tailing indicates that the reader is at the current journal write head,
  // and hints that the next ShuffleResponse may block indefinitely while
  // waiting for more documents to be written.
  bool tailing = 5;
}

service Shuffler {
  rpc Shuffle(ShuffleRequest) returns (stream ShuffleResponse);
}

enum DeriveState {
  // IDLE indicates the transaction has not yet begun.
  // IDLE transitions to EXTEND.
  IDLE = 0;
  // EXTEND extends the derive transaction with additional
  // source or derived collection documents.
  //
  // * The flow consumer sends any number of EXTEND DeriveRequests,
  //   containing source collection documents.
  // * Concurrently, the derive worker responds with any number of
  //   EXTEND DeriveResponses, each having documents to be added to
  //   the collection being derived.
  // * The flow consumer is responsible for publishing each derived
  //   document to the appropriate collection & partition.
  // * Note that DeriveRequest and DeriveResponse EXTEND messages are _not_ 1:1.
  //
  // EXTEND transitions to EXTEND or FLUSH.
  EXTEND = 1;
  // FLUSH indicates the transacton pipeline is to flush.
  //
  // * The flow consumer issues FLUSH when its consumer transaction begins to
  //   close.
  // * The derive worker responds with FLUSH to indicate that all source
  //   documents have been processed and all derived documents emitted.
  // * The flow consumer awaits the response FLUSH, while continuing to begin
  //   publish operations for all derived documents seen in the meantime.
  // * On seeing FLUSH, the flow consumer is assured it's sequenced and started
  //   publishing all derived documents of the transaction, and can now build
  //   the consumer.Checkpoint which will be committed to the store.
  //
  // FLUSH transitions to PREPARE.
  FLUSH = 2;
  // PREPARE begins a commit of the transaction.
  //
  // * The flow consumer sends PREPARE with its consumer.Checkpoint.
  // * On receipt, the derive worker queues an atomic recoverylog.Recorder
  //   block that's conditioned on an (unresolved) "commit" future. Within
  //   this recording block, underlying store commits (SQLite COMMIT and writing
  //   a RocksDB WriteBatch) are issued to persist all state changes of the
  //   transaction, along with the consumer.Checkpoint.
  // * The derive worker responds with PREPARE once all local commits have
  //   completed, and recoverylog writes have been queued (but not started,
  //   awaiting COMMIT).
  // * On receipt, the flow consumer arranges to invoke COMMIT on the completion
  //   of all outstanding journal writes -- this the OpFuture passed to the
  //   Store.StartCommit interface. It returns a future which will resolve only
  //   after reading COMMIT from this transaction -- the OpFuture returned by
  //   that interface.
  //
  // It's an error if a prior transaction is still running at the onset of
  // PREPARE. However at the completion of PREPARE, a new & concurrent
  // Transaction may begin, though it itself cannot PREPARE until this
  // Transaction fully completes.
  //
  // PREPARE transitions to COMMIT.
  PREPARE = 3;
  // COMMIT commits the transaction by resolving the "commit" future created
  // during PREPARE, allowing the atomic commit block created in PREPARE
  // to flush to the recovery log. The derive worker responds with COMMIT
  // when the commit barrier has fully resolved.
  //
  // COMMIT transitions to stream close.
  COMMIT = 4;
}

// DeriveRequest is the streamed message of a Derive RPC.
message DeriveRequest {
  DeriveState state = 1;

  // Source collection documents to derive from. Set iff state == EXTEND.
  repeated Document documents = 2 [ (gogoproto.nullable) = false ];
  // Checkpoint to commit. Set iff state == PREPARE.
  consumer.Checkpoint checkpoint = 4;
}

// DeriveResponse is the streamed response message of a Derive RPC.
message DeriveResponse {
  DeriveState state = 1;

  // Documents derived from request documents. Set iff state == EXTEND.
  repeated Document documents = 2 [ (gogoproto.nullable) = false ];
  // Names of associated logical partition fields extracted from |documents|.
  // Arity and ordering matches Document.fields.
  repeated string field_names = 3;
};

message ExtractRequest {
  // Documents to extract from.
  repeated Document documents = 1 [ (gogoproto.nullable) = false ];
  // JSON pointer of document UUID to extract.
  string uuid_ptr = 2;
  // Hash is a composite of JSON pointers to extract & hash.
  message Hash {
    repeated string ptrs = 1;
  }
  repeated Hash hashes = 3 [ (gogoproto.nullable) = false ];
  // Field names and JSON pointers to extract from documents.
  message Field {
    // Name of field to extract.
    string name = 1;
    // JSON Pointer of field location within documents.
    string ptr = 2;
  }
  repeated Field fields = 4;
};

// Field holds values extracted for a given named Document field.
message Field {
  // Name of this field .
  string name = 1;
  // Value is the extracted representation fo the field value.
  message Value {
    enum Type {
      INVALID = 0;
      NULL = 1;
      TRUE = 2;
      FALSE = 3;
      STRING = 4;
      UNSIGNED = 5;
      SIGNED = 6;
      NUMBER = 7;
      OBJECT = 8;
      ARRAY = 9;
    }
    Type type = 1;

    string string = 2;
    uint64 unsigned = 3;
    int64 signed = 4;
    float number = 5;
    bytes object = 6;
    bytes array = 7;
  };
  repeated Value values = 2 [(gogoproto.nullable) = false ];
}

// Hash holds hashes extracted for a given Hash key of Documents.
message Hash {
  repeated fixed32 values = 1;
}

message ExtractResponse {
  // UUIDParts extracted from request Documents.
  repeated UUIDParts uuid_parts = 5 [ (gogoproto.nullable) = false ];
  // Hashes extracted from request Documents, one column for each requested Hash.
  repeated Hash hashes = 2 [ (gogoproto.nullable) = false ];
  // Fields extracted from request Documents, one column for each requested Field.
};

service Derive {
  // RestoreCheckpoint recovers the most recent Checkpoint previously committed
  // to the Store. It is called just once, at Shard start-up. If an external
  // system is used, it should install a transactional "write fence" to ensure
  // that an older Store instance of another process cannot successfully
  // StartCommit after this RestoreCheckpoint returns.
  rpc RestoreCheckpoint(google.protobuf.Empty) returns (consumer.Checkpoint);

  // Derive begins a pipelined derive transaction, following the
  // state machine detailed in DeriveState.
  rpc Derive(stream DeriveRequest) returns (stream DeriveResponse);

  // BuildHints returns FSMHints which may be played back to fully reconstruct
  // the local filesystem state produced by this derive worker. It may block
  // while pending operations sync to the recovery log.
  rpc BuildHints(google.protobuf.Empty) returns (recoverylog.FSMHints);

  rpc Extract(ExtractRequest) returns (ExtractResponse);
}
